{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I have created ResNet based on https://arxiv.org/pdf/1603.05027.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y_true):\n",
    "    '''\n",
    "    Use this function to check accuracy of a model trained.\n",
    "    \n",
    "    :param: preds - predictions generated by neural network\n",
    "    :param: y_true - true/real labels for each sample in the dataset\n",
    "    '''\n",
    "    correct = 0 \n",
    "    assert len(preds) == len(y_true)\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        if np.argmax(preds[i]) == y_true[i]:\n",
    "            correct += 1\n",
    "    return correct / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparams\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "hidden_units = 256\n",
    "number_of_res_blocks = 10\n",
    "between_strides = number_of_res_blocks/3\n",
    "int(between_strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root='./data/', \n",
    "                      train=True, \n",
    "                      transform=transforms.ToTensor(), \n",
    "                      download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='./data/', \n",
    "                      train=False, \n",
    "                      transform=transforms.ToTensor(), \n",
    "                      download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False, \n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Residual block class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(ResBlock, self).__init__()\n",
    "        #We will set default 32 to be number of filters/units in ResBlock\n",
    "        self.b_1 = nn.BatchNorm2d(32)\n",
    "        self.conv_1 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.b_2 = nn.BatchNorm2d(32)\n",
    "        self.conv_2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.b_1(X)\n",
    "        out = f.relu(out)\n",
    "        out = self.conv_1(out)\n",
    "        out = self.b_2(out)\n",
    "        out = f.relu(out)\n",
    "        out = self.conv_2(out)\n",
    "        return X + out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESIDUAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, between_strides, number_of_res_blocks, number_of_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.input_layer = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.res_layers = []\n",
    "        for i in range(int(number_of_res_blocks/between_strides)):\n",
    "            for j in range(int(between_strides)):\n",
    "                self.res_layers.append(ResBlock())\n",
    "            #Make strided layer\n",
    "            self.res_layers.append(nn.Conv2d(32, 32, kernel_size=3, stride=2))\n",
    "            self.res_layers.append(nn.BatchNorm2d(32))\n",
    "        \n",
    "        self.output_layer = nn.Linear(32*2*2, number_of_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.input_layer(X)\n",
    "        for i in range(len(self.res_layers)):\n",
    "            out = self.res_layers[i](out)\n",
    "            \n",
    "        out = out.view(-1, 32*2*2)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = ResNet(between_strides, number_of_res_blocks, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (input_layer): Conv2d (1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (output_layer): Linear(in_features=128, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), Conv2d (32, 32, kernel_size=(3, 3), stride=(2, 2)), BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), Conv2d (32, 32, kernel_size=(3, 3), stride=(2, 2)), BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), ResBlock(\n",
       "   (b_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_1): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (b_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "   (conv_2): Conv2d (32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ), Conv2d (32, 32, kernel_size=(3, 3), stride=(2, 2)), BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_net.res_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(res_net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10  | Epoch loss: 0.5831528902053833  | Epoch accuracy: 0.8496875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-140cd0fea3ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lukaa\\appdata\\local\\continuum\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lukaa\\appdata\\local\\continuum\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m---> 99\u001b[1;33m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_accuracy = []\n",
    "    epoch_loss = []\n",
    "    counter = 0\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        X_batch = Variable(images)\n",
    "        y_batch = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = res_net(X_batch)\n",
    "        epoch_accuracy.append(accuracy(preds.cpu().data.numpy(), y_batch.cpu().data.numpy()))\n",
    "        loss = criterion(preds, y_batch)\n",
    "        epoch_loss.append(loss.cpu().data.numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:\n",
    "            print(\"Epoch: {}/{}\".format(epoch+1, epochs), \n",
    "                  \" | Epoch loss: {}\".format(np.mean(epoch_loss)), \n",
    "                  \" | Epoch accuracy: {}\".format(np.mean(epoch_accuracy)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
