{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just a demonstration on how to build RNN in PyTorch.\n",
    "\n",
    "Dataset used for this demonstration is: Fashion Mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import FashionMNIST\n",
    "import torchvision.transforms as transforms \n",
    "from torch.optim import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y_true):\n",
    "    '''\n",
    "    Use this function to check accuracy of a model trained.\n",
    "    \n",
    "    :param: preds - predictions generated by neural network\n",
    "    :param: y_true - true/real labels for each sample in the dataset\n",
    "    '''\n",
    "    correct = 0 \n",
    "    assert len(preds) == len(y_true)\n",
    "    \n",
    "    for i in range(len(preds)):\n",
    "        if np.argmax(preds[i]) == y_true[i]:\n",
    "            correct += 1\n",
    "    return correct / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "learning_rate = 0.003\n",
    "num_epochs = 6\n",
    "batch_size = 100\n",
    "rnn_size = 128\n",
    "seq_len = 28\n",
    "in_vector_size = 28\n",
    "num_layers = 2\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and transform FashionMNIST training set\n",
    "train_data = FashionMNIST(root='./data/', \n",
    "                          train=True, \n",
    "                          transform=transforms.ToTensor(), \n",
    "                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack and transform FashionMNIST test set\n",
    "test_data = FashionMNIST(root='./data/', \n",
    "                          train=False, \n",
    "                          transform=transforms.ToTensor(), \n",
    "                          download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a training set loader - DataLoader will help us with batching a dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a test set loader\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False, \n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create RNN in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_of_classes, rnn_size, number_of_layers):\n",
    "        '''\n",
    "            Init function of the SimpleRNN class helps to setup everything that we need for rnn.\n",
    "            \n",
    "            :param: input_size - size of input vector\n",
    "            :param: rnn_size - number of units/neurons in the RNN\n",
    "            :param: number_of_layers - number of RNN layers\n",
    "            :param: num_of_classes - number of different classes in a dataset (e.p. MNIST has 10 classes)\n",
    "        '''\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_units = rnn_size\n",
    "        self.num_layers = number_of_layers\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size, rnn_size, number_of_layers, batch_first=True)\n",
    "        self.out_layer = nn.Linear(self.hidden_units, num_of_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        This method is called for networks forward-prop.\n",
    "        \n",
    "        :param: X - batch of data from a dataset\n",
    "        '''\n",
    "     \n",
    "        #Create starting states for the LSTM layer\n",
    "        h0 = Variable(torch.zeros(self.num_layers, X.size(0), self.hidden_units).cuda())\n",
    "        c0 = Variable(torch.zeros(self.num_layers, X.size(0), self.hidden_units).cuda())\n",
    "        \n",
    "        out, _ = self.rnn(X, (h0, c0))\n",
    "        \n",
    "        out = f.softmax(self.out_layer(out[:, -1, :]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RNN network object\n",
    "rnn = SimpleRNN(in_vector_size, num_classes, rnn_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (rnn): LSTM(28, 128, num_layers=2, batch_first=True)\n",
       "  (out_layer): Linear(in_features=128, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you have avaliable cuda supported GPU card use this command to run the network on GPU instead of CPU\n",
    "rnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of the Adam optimizer\n",
    "optimizer = Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lukaa\\appdata\\local\\continuum\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/6  | Epoch loss: 1.7887852191925049  | Epoch accuracy: 0.67635\n",
      "Epoch: 2/6  | Epoch loss: 1.7101843357086182  | Epoch accuracy: 0.7513166666666666\n",
      "Epoch: 3/6  | Epoch loss: 1.677836298942566  | Epoch accuracy: 0.7833833333333333\n",
      "Epoch: 4/6  | Epoch loss: 1.660081386566162  | Epoch accuracy: 0.8012666666666667\n",
      "Epoch: 5/6  | Epoch loss: 1.652994155883789  | Epoch accuracy: 0.8082833333333334\n",
      "Epoch: 6/6  | Epoch loss: 1.6279258728027344  | Epoch accuracy: 0.8331833333333334\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_accuracy = []\n",
    "    epoch_loss = []\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        X_batch = Variable(images.view(-1, seq_len, in_vector_size)).cuda()\n",
    "        y_batch = Variable(labels).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        preds = rnn(X_batch)\n",
    "        epoch_accuracy.append(accuracy(preds.cpu().data.numpy(), y_batch.cpu().data.numpy()))\n",
    "        loss = criterion(preds, y_batch)\n",
    "        epoch_loss.append(loss.cpu().data.numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: {}/{}\".format(epoch+1, num_epochs), \n",
    "          \" | Epoch loss: {}\".format(np.mean(epoch_loss)), \n",
    "          \" | Epoch accuracy: {}\".format(np.mean(epoch_accuracy)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
