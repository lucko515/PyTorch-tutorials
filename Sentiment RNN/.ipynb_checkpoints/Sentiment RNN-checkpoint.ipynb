{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I have implemented sentiment analysis with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, real):\n",
    "    '''\n",
    "    Call this function to measure accuracy of the model for binary classification task.\n",
    "    \n",
    "    :param: pred - predictions got from a model\n",
    "    :param: real - real labels for each sample in the dataset\n",
    "    '''\n",
    "    assert len(pred) == len(real)\n",
    "    correct = 0 \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] >= 0.5:\n",
    "            if real[i] == 1:\n",
    "                correct += 1\n",
    "        else:\n",
    "            if real[i] == 0:\n",
    "                correct += 1\n",
    "    \n",
    "    return correct / len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Preprocessing dataset\n",
    "\n",
    "To work properly with the dataset that I've choosen for this notebook there are several steps that we have to perform.\n",
    "       \n",
    "       1. Clean punctuation and lower all characters in the dataset\n",
    "       2. Delete stopwords\n",
    "       3. Split each sample to words\n",
    "       4. Encode each word to vocabulary index\n",
    "       5. Split training data into training and validation (small_test) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lukaa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you have just PIP-ed nltk, you will need to download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#Here are all stopwords for english language\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1 Load dataset from csv file and separate it to features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('training.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                           Sentence\n",
       "0      1            The Da Vinci Code book is just awesome.\n",
       "1      1  this was the first clive cussler i've ever rea...\n",
       "2      1                   i liked the Da Vinci Code a lot.\n",
       "3      1                   i liked the Da Vinci Code a lot.\n",
       "4      1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.Class.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.Sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The Da Vinci Code book is just awesome.',\n",
       "       \"this was the first clive cussler i've ever read, but even books like Relic, and Da Vinci code were more plausible than this.\",\n",
       "       'i liked the Da Vinci Code a lot.', ...,\n",
       "       'As I sit here, watching the MTV Movie Awards, I am reminded of how much I despised the movie Brokeback Mountain.',\n",
       "       'Ok brokeback mountain is such a horrible movie.',\n",
       "       'Oh, and Brokeback Mountain was a terrible movie.'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2 Clean data from all punctuation and change all character to the lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataset):\n",
    "    '''\n",
    "        Use this function to lower all samples and delete all punctuations from a dataset.\n",
    "        \n",
    "        :param: dataset - unprocessed dataset\n",
    "        :return: cleaned_dataset - where each sample is lower case and without punctuations\n",
    "    '''\n",
    "    cleaned_dataset = []\n",
    "    for s in dataset:\n",
    "        cleaned_sample = s.lower() #to lowercase\n",
    "        cleaned_sample = re.sub(r'[^\\w\\s]','',cleaned_sample) #delete all punctuation\n",
    "        cleaned_dataset.append(cleaned_sample)\n",
    "    return np.array(cleaned_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleand_features = clean_data(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the da vinci code book is just awesome',\n",
       "       'this was the first clive cussler ive ever read but even books like relic and da vinci code were more plausible than this',\n",
       "       'i liked the da vinci code a lot', ...,\n",
       "       'as i sit here watching the mtv movie awards i am reminded of how much i despised the movie brokeback mountain',\n",
       "       'ok brokeback mountain is such a horrible movie',\n",
       "       'oh and brokeback mountain was a terrible movie'], dtype='<U4637')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleand_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.3 Delete all stopwords and split each sample in the dataset into words | create vocab, word_to_id and id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data):\n",
    "    '''\n",
    "    Call this function on cleaned dataset to tokenize it and create vocab for the dataset.\n",
    "    \n",
    "    :param: data -  cleaned_dataset\n",
    "    :return: tokenized_data - dataset where each sample has been splited into words\n",
    "    :return: word_to_id - dict where each key is word from vocab and value is its index\n",
    "    :return: id_to_word - dict where each key is index of word from vocab and value is the word on that index\n",
    "    :return: vocab - list of all unique words in this dataset\n",
    "    '''\n",
    "    all_words = []\n",
    "    tokenized_data = []\n",
    "    for s in data:\n",
    "        words = s.split()\n",
    "        tokenized_sample = []\n",
    "        for word in words:\n",
    "            if word not in stopwords.words('english'):\n",
    "                tokenized_sample.append(word)\n",
    "                all_words.append(word)\n",
    "            \n",
    "        tokenized_data.append(np.array(tokenized_sample))\n",
    "        \n",
    "    counter = Counter(all_words)\n",
    "    vocab = sorted(counter, key=counter.get, reverse=True)\n",
    "    \n",
    "    word_to_id = {word:i for i, word in enumerate(vocab)}\n",
    "    id_to_word = {i:word for i, word in enumerate(vocab)}\n",
    "    \n",
    "    return np.array(tokenized_data), word_to_id, id_to_word, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data, word_to_id, id_to_word, vocab = tokenizer(cleand_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['da', 'vinci', 'code', 'book', 'awesome'], dtype='<U7'),\n",
       "       array(['first', 'clive', 'cussler', 'ive', 'ever', 'read', 'even',\n",
       "       'books', 'like', 'relic', 'da', 'vinci', 'code', 'plausible'],\n",
       "      dtype='<U9'),\n",
       "       array(['liked', 'da', 'vinci', 'code', 'lot'], dtype='<U5'), ...,\n",
       "       array(['sit', 'watching', 'mtv', 'movie', 'awards', 'reminded', 'much',\n",
       "       'despised', 'movie', 'brokeback', 'mountain'], dtype='<U9'),\n",
       "       array(['ok', 'brokeback', 'mountain', 'horrible', 'movie'], dtype='<U9'),\n",
       "       array(['oh', 'brokeback', 'mountain', 'terrible', 'movie'], dtype='<U9')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.4 Encoded each word into its index in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_helper(sample, seq_len):\n",
    "    '''\n",
    "    This method is used to for padding samples that are shorter then given sequence_length\n",
    "    :param: sample - dataset sample that needs to be chacked\n",
    "    :param: seq_len - wanted number of tokens (words) in each dataset sample\n",
    "    :return: edited sample\n",
    "    '''\n",
    "    if len(sample) > seq_len:\n",
    "        return sample[:seq_len]\n",
    "    else:\n",
    "        return [0]*(seq_len-len(sample)) + sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(data, word_to_id, seq_len):\n",
    "    '''\n",
    "    Call this method to encode dataset.\n",
    "    \n",
    "    :param: data - tokenized data\n",
    "    :param: word_to_id - dict where each key is word from vocab and value is its index\n",
    "    :param: seq_len - wanted number of tokens (words) in each dataset sample\n",
    "    :return: encoded dataset\n",
    "    '''\n",
    "    encoded_data = []\n",
    "    for s in data:\n",
    "        encoded_sample = []\n",
    "        for word in s:\n",
    "            encoded_sample.append(word_to_id[word])\n",
    "        \n",
    "        encoded_data.append(np.array(encoder_helper(encoded_sample, seq_len)))\n",
    "    \n",
    "    return np.array(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder(tokenized_data, word_to_id, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.5 Split dataset into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_creator(data, in_labels, test_size=0.2):\n",
    "    '''\n",
    "    Hlper function used as a wrapper for sklear functions to split a dataset into training and testing parts\n",
    "    \n",
    "    :param: data - dataset\n",
    "    :param: in_labels - labels for the dataset\n",
    "    :param: test_size - pecentage of a dataset that will be used as a testing dataset\n",
    "    '''\n",
    "    shuffled_features, shuffled_labels = shuffle(data, in_labels)\n",
    "    \n",
    "    return train_test_split(shuffled_features, shuffled_labels, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_creator(encoded_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparams\n",
    "epochs = 3\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "embed_vector = 300\n",
    "vocab_size = len(word_to_id)\n",
    "rnn_size = 256\n",
    "number_of_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 RNN-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, rnn_size, number_of_layers):\n",
    "    \n",
    "        super(SentimentRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_units = rnn_size\n",
    "        self.number_of_layers = number_of_layers\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, rnn_size, number_of_layers, batch_first=True)\n",
    "        \n",
    "        self.out_layer = nn.Linear(self.hidden_units, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        h0 = Variable(torch.zeros(self.number_of_layers, X.size(0), self.hidden_units).cuda())\n",
    "        c0 = Variable(torch.zeros(self.number_of_layers, X.size(0), self.hidden_units).cuda())\n",
    "        \n",
    "        out, _ = self.lstm(self.embed(X), (h0, c0))\n",
    "        \n",
    "        out = F.sigmoid(self.out_layer(out[:, -1, :]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of the model for wanted hyperparams\n",
    "model = SentimentRNN(vocab_size, embed_vector, rnn_size, number_of_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentRNN(\n",
       "  (embed): Embedding(2116, 300)\n",
       "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True)\n",
       "  (out_layer): Linear(in_features=256, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you have GPU that is cuda supported execute this cell\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2 Setup of loss function\n",
    "\n",
    "For this tast we will use Binary Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.3 Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Training and testing\n",
    "\n",
    "\n",
    "#### Step 3.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lukaa\\appdata\\local\\continuum\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1168: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/3  | Accuracy: 0.90625  | Loss: 0.20403729379177094\n",
      "Epoch: 1/3  | Accuracy: 0.9943677325581395  | Loss: 0.02016657590866089\n",
      "Epoch: 2/3  | Accuracy: 0.998546511627907  | Loss: 0.0049927267245948315\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_accuracy = []\n",
    "    epoch_loss = []\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "        starting_id = i * batch_size\n",
    "        ending_id = starting_id + batch_size\n",
    "        \n",
    "        X_batch = Variable(torch.from_numpy(X_train[starting_id:ending_id])).cuda()\n",
    "        y_batch = Variable(torch.from_numpy(np.float32(y_train[starting_id:ending_id]))).cuda()\n",
    "        X_batch = X_batch.type(torch.cuda.LongTensor)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_batch)\n",
    "        \n",
    "        epoch_accuracy.append(accuracy(pred.cpu().data.numpy(), y_batch.cpu().data.numpy()))\n",
    "        \n",
    "        loss = criterion(pred, y_batch)\n",
    "        epoch_loss.append(loss.cpu().data.numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: {}/{}\".format(epoch, epochs),\n",
    "          \" | Accuracy: {}\".format(np.mean(epoch_accuracy)), \n",
    "          \" | Loss: {}\".format(np.mean(epoch_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.2 Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuray = []\n",
    "for i in range(len(X_test) // batch_size):\n",
    "    starting_id = i * batch_size\n",
    "    ending_id = starting_id + batch_size\n",
    "\n",
    "    X_batch = Variable(torch.from_numpy(X_test[starting_id:ending_id])).cuda()\n",
    "    y_batch = Variable(torch.from_numpy(np.float32(y_test[starting_id:ending_id]))).cuda()\n",
    "    X_batch = X_batch.type(torch.cuda.LongTensor)\n",
    "\n",
    "    pred = model(X_batch)\n",
    "\n",
    "    test_accuray.append(accuracy(pred.cpu().data.numpy(), y_batch.cpu().data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98828125"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_accuray) # This is nice accuracy for the testing set :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
